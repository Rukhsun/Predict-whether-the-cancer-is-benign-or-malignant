{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python for Data Science CSCI E - 29\n",
    "Natural Language Identification Machine Learning Pipeline - Graduate Project\n",
    "In this project, I pulled text data from European Parliament Proceedings in 21 languages. Using Scikit-Learn, I transformed the raw text into a numerical feature matrix, and trained a Multinomial naive bayes probability model to classify input language with greater than 99% accuracy. \n",
    "Data Source: http://www.statmt.org/europarl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=r'<(!?).*>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_TRANSCRIPTION=150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map language index to natural language\n",
    "\n",
    "labels = { \n",
    "          1.0:'Danish', 2.0:'German',\n",
    "          3.0: 'Greek', 4.0: 'English', \n",
    "          5.0: 'Spanish',6.0: 'Finnish', \n",
    "          7.0: 'French', 8.0: 'Italian', \n",
    "          9.0: 'Dutch', 10.0: 'Portuguese', \n",
    "          11.0: 'Swedish', 12.0: 'Bulgarian',\n",
    "          13.0: 'Czech', 14.0: 'Estonian',\n",
    "          15.0: 'Hungarian', 16.0: 'Lithuanian',\n",
    "          17.0: 'Latvian', 18.0: 'Polish',\n",
    "          19.0: 'Romanian', 20.0: 'Slovak',\n",
    "          21.0: 'Slovenian'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map language to language code and file name\n",
    "\n",
    "language_codes_files = {\n",
    "    'Danish': ['da', '/ep-00-01-17.txt'], 'German': ['de', '/ep-00-01-17.txt'], \n",
    "    'Greek': ['el', '/ep-00-01-17.txt'], 'English': ['en', '/ep-00-01-17.txt'], \n",
    "    'Spanish': ['es', '/ep-00-01-17.txt'], 'Finnish': ['fi', '/ep-00-01-17.txt'],\n",
    "    'French': ['fr','/ep-00-01-17.txt'], 'Italian': ['it', '/ep-00-01-17.txt'], \n",
    "    'Dutch': ['nl', '/ep-00-01-17.txt'], 'Portuguese': ['pt', '/ep-00-01-17.txt'], \n",
    "    'Swedish': ['sv', '/ep-00-01-17.txt'], 'Bulgarian': ['bg', '/Bulgarian.txt'],\n",
    "    'Czech': ['cs', '/Czech.txt'], 'Estonian': ['et', '/Estonian.txt'],\n",
    "    'Hungarian': ['hu', '/Hungarian.txt'], 'Lithuanian': ['lt', '/Lithuanian.txt'],\n",
    "    'Latvian': ['lv', '/Latvian.txt'], 'Polish': ['pl', '/Polish.txt'],\n",
    "    'Romanian': ['ro', '/Romanian.txt'], 'Slovak': ['sk', '/Slovak.txt'],\n",
    "    'Slovenian': ['sl', '/Slovenian.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These languages need multiple files combined to get a transcription of length\n",
    "# >= MAX_LENGTH_TRANSCRIPTION\n",
    "limited_raw_text = ['Bulgarian', 'Czech', 'Estonian', 'Hungarian', 'Lithuanian',\n",
    "                     'Latvian', 'Polish', 'Romanian', 'Slovak', 'Slovenian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
